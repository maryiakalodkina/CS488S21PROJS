//All those answers are not complete and are written late late in the night
so might note make any sense. It's just a tired draft.
 
 For Q2 we assume that the expected latency would be 177.519 ms as that is what 
we get if we sum up L1 avg rtt (86.797 ms), L2 avg rtt (25.667 ms), 
L3 avg rtt (65.056 ms).
 Actual measured latency (avg RRT) is 172.309 ms. 

 For Q2 we assume that the expected throughput would be the sum of 3 bandwidth
of L1,L2 and L3 (11.1637 Mbps + 33.3079 Mbps + 24.7955 Mbps) divided by 3, which would 
give us 23.0890 Mbps 
 Actual measured throughput is 18.2243 Mbps. The actual throughtput is lower 
than the expected throughput as it can be affected by many factors like 
latency, transmission medium limitation, etc. 

 For Q3 we assume that the expected latency would double the actual 
measured latency for L1+L2+L3 (172.309 ms) because we made two pairs of hosts 
run on the same switched (thus, links) simultaneously.
 Similar way, the expected latency for 3 simultaneous pairs would be 
 172 ms * 3 = 516 ms 
However, the actual measured latency did not get affected by the 
simultaneously  run neither when we ran 2 pairs nor when 3 
and showed us the result of avg rtt approximately 175 ms. 

For Q3 we assume that the throughput would be affected by the 
simultaneous communication of 2 pairs and will be cut in half -> 
approximately 9 Mbps.
Similar, for simultaneous communication of 3 pairs, it would be cut in 1/3 ->
approximately 6 Mbps.
However, after running 2 pairs simultaneously to check, we learnt that the 
throughput did not get affected and stayed approximately 17 Mbps for all 
the pairs. EXPLAIN WHY

For Q4 we assume that the throughput would not be affected based on the
previous examples. Thus, for h1-h4 the latency will remain approximately 
172 ms, and for h5-h6 the latency would be 14.455 (L4) + 25.667 (L2) 
+ 14.774 (L5)= 54.896 ms.
 
Q4 Assumtions: throughput would not be changed
Q4 Actual: throughput wasn't affected
